{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygraphblas import *\n",
    "from pygraphblas.demo.gviz import draw, draw_op\n",
    "import pygraphblas.descriptor\n",
    "import csv\n",
    "import sys\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data from CSV format\n",
    "class DataLoader:\n",
    "    \n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        \n",
    "    def load_node(self, filename):\n",
    "        filename = self.path + filename\n",
    "        with open(filename, newline='') as csvfile:\n",
    "            reader = csv.DictReader(csvfile, delimiter=',', quotechar='\"')\n",
    "            original_ids = [row['id:ID'] for row in reader]\n",
    "            id_mapping = {}\n",
    "            for index in range(len(original_ids)):\n",
    "                id_mapping[original_ids[index]] = index\n",
    "            \n",
    "        return original_ids, id_mapping\n",
    "\n",
    "    def load_edge(self, filename, start_mapping, end_mapping, typ=BOOL, drop_dangling_edges=False):\n",
    "        filename = self.path + filename\n",
    "        with open(filename, newline='') as csvfile:\n",
    "            reader = csv.DictReader(csvfile, delimiter=',', quotechar='\"')\n",
    "            row_ids = []\n",
    "            col_ids = []\n",
    "            values = []\n",
    "            for row in reader:\n",
    "                start_id = row['id:START_ID']\n",
    "                end_id = row['id:END_ID']\n",
    "                if not drop_dangling_edges or (start_id in start_mapping and end_id in end_mapping):\n",
    "                    row_ids.append(start_mapping[start_id])\n",
    "                    col_ids.append(end_mapping[end_id])\n",
    "                    values.append(1)\n",
    "        \n",
    "            edge_matrix = Matrix.from_lists(\n",
    "            row_ids,\n",
    "            col_ids,\n",
    "            values,\n",
    "            nrows=len(start_mapping), \n",
    "            ncols=len(end_mapping), \n",
    "            typ=typ)\n",
    "            return edge_matrix\n",
    "\n",
    "def print_data_dimensions(vertices, matrices):\n",
    "    for vertex in vertices:\n",
    "        print(f\"dimension of {vertex} is {len(vertices[vertex])}\")\n",
    "    \n",
    "    for matrix in matrices:\n",
    "        print(f\"dimension of {matrix} is {matrices[matrix].shape}\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension of Route is 10\n",
      "dimension of SwitchPosition is 67\n",
      "dimension of Switch is 67\n",
      "dimension of Sensor is 310\n",
      "dimension of Segment is 1564\n",
      "dimension of Semaphore is 10\n",
      "dimension of follows is (10, 67)\n",
      "dimension of target is (67, 67)\n",
      "dimension of monitoredBySwitch is (67, 310)\n",
      "dimension of monitoredBySegment is (1564, 310)\n",
      "dimension of monitoredBy is (1631, 310)\n",
      "dimension of requires is (10, 310)\n",
      "dimension of connectsToSeg is (1564, 1564)\n",
      "dimension of connectsToTrackElem is (1631, 1631)\n",
      "dimension of exit is (10, 10)\n",
      "dimension of entry is (10, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Matrix (10x10 : 27:BOOL)>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Check results here:\n",
    "https://github.com/ftsrg/trainbenchmark/blob/master/trainbenchmark-tool/src/main/java/hu/bme/mit/trainbenchmark/benchmark/test/TrainBenchmarkTest.java#L139 \n",
    "'''\n",
    "\n",
    "path = 'trainbenchmark-repair-models-csv/'\n",
    "loader = DataLoader(path)\n",
    "data_size = 2\n",
    "\n",
    "vertices = {}\n",
    "mapping = {}\n",
    "vertices['Route'], mapping['Route'] = loader.load_node(f'railway-repair-{data_size}-Route.csv')\n",
    "vertices['SwitchPosition'], mapping['SwitchPosition'] = loader.load_node(f'railway-repair-{data_size}-SwitchPosition.csv')\n",
    "vertices['Switch'], mapping['Switch'] = loader.load_node(f'railway-repair-{data_size}-Switch.csv')\n",
    "vertices['Sensor'], mapping['Sensor'] = loader.load_node(f'railway-repair-{data_size}-Sensor.csv')\n",
    "vertices['Segment'], mapping['Segment'] = loader.load_node(f'railway-repair-{data_size}-Segment.csv')\n",
    "vertices['Semaphore'], mapping['Semaphore'] = loader.load_node(f'railway-repair-{data_size}-Semaphore.csv')\n",
    "\n",
    "matrices = {}\n",
    "matrices['follows'] = loader.load_edge(f'railway-repair-{data_size}-follows.csv', mapping['Route'], mapping['SwitchPosition'])\n",
    "matrices['target'] = loader.load_edge(f'railway-repair-{data_size}-target.csv', mapping['SwitchPosition'], mapping['Switch'])\n",
    "matrices['monitoredBySwitch'] = loader.load_edge(f'railway-repair-{data_size}-monitoredBy.csv', mapping['Switch'], mapping['Sensor'], drop_dangling_edges=True)\n",
    "matrices['monitoredBySegment'] = loader.load_edge(f'railway-repair-{data_size}-monitoredBy.csv', mapping['Segment'], mapping['Sensor'], drop_dangling_edges=True)\n",
    "matrices['monitoredBy'] = loader.load_edge(f'railway-repair-{data_size}-monitoredBy.csv', {**mapping['Segment'], **mapping['Switch']}, mapping['Sensor'], drop_dangling_edges=False)\n",
    "matrices['requires'] = loader.load_edge(f'railway-repair-{data_size}-requires.csv', mapping['Route'], mapping['Sensor'])\n",
    "matrices['connectsToSeg'] = loader.load_edge(f'railway-repair-{data_size}-connectsTo.csv', mapping['Segment'], mapping['Segment'], drop_dangling_edges=True)\n",
    "matrices['connectsToTrackElem'] = loader.load_edge(f'railway-repair-{data_size}-connectsTo.csv', {**mapping['Segment'], **mapping['Switch']}, {**mapping['Segment'], **mapping['Switch']}, drop_dangling_edges=False)\n",
    "matrices['exit'] = loader.load_edge(f'railway-repair-{data_size}-exit.csv', mapping['Route'], mapping['Semaphore'])\n",
    "matrices['entry'] = loader.load_edge(f'railway-repair-{data_size}-entry.csv', mapping['Route'], mapping['Semaphore'])\n",
    "\n",
    "print_data_dimensions(vertices, matrices)\n",
    "\n",
    "#Uncomment to trace down specific Sensor\n",
    "#selected_sensor_id = mapping['Sensor']['1692']\n",
    "\n",
    "def route_sensor_violation_query(matrices):\n",
    "    route_to_switch = matrices['follows'] @ matrices['target']\n",
    "    route_to_sensor = route_to_switch @ matrices['monitoredBySwitch']\n",
    "    return route_to_sensor.extract_matrix(matrices['requires'], desc=descriptor.ooco)\n",
    "\n",
    "\n",
    "def connected_segments_query(matrices, vertices):\n",
    "    monitoredBySegmentTransposed = matrices['monitoredBySegment'].transpose()\n",
    "    res = monitoredBySegmentTransposed.dup()\n",
    "    for _ in range(5):\n",
    "        #I, J, V = res[[selected_sensor_id],:].to_lists()\n",
    "        #print([vertices['Segment'][j] for j in J])\n",
    "        res = res.mxm(matrices['connectsToSeg'], mask=monitoredBySegmentTransposed)\n",
    "        \n",
    "    I, J, V = res.to_lists()\n",
    "    violating_sensor_ids = [vertices['Sensor'][i] for i in I]\n",
    "    print('The IDs of the sensors that violate the constraints:')\n",
    "    print(violating_sensor_ids)\n",
    "    print(f'The total number of violations is {len(res)}')\n",
    "              \n",
    "def switch_monitored_query(matrices):\n",
    "    return matrices['monitoredBy']\n",
    "\n",
    "def semaphore_neighbor_query(matrices):    \n",
    "    monitoredByTransposed = matrices['monitoredBy'].transpose()\n",
    "    connectsToTrackElemTransposed = matrices['connectsToTrackElem'].transpose()\n",
    "    requiresTransposed = matrices['requires'].transpose()\n",
    "\n",
    "    route_to_trackelement1 = matrices['requires'] @ monitoredByTransposed\n",
    "    route_to_trackelement2 = route_to_trackelement1 @ connectsToTrackElemTransposed\n",
    "    route_to_sensor = route_to_trackelement2 @ matrices['monitoredBy']\n",
    "    route_to_route_ = route_to_sensor @ requiresTransposed \n",
    "    route_to_route = route_to_route_.offdiag()\n",
    "    route_to_semaphore = route_to_route @ matrices['exit']\n",
    "    return route_to_semaphore.extract_matrix(mask=matrices['entry'], desc=descriptor.ooco)\n",
    "\n",
    "\n",
    "semaphore_neighbor_query(matrices)\n",
    "\n",
    "# connected_segments_query(matrices, vertices)\n",
    "# route_sensor_violations_result = route_sensor_violation_query(matrices)\n",
    "# print(len(route_sensor_violations_result))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(route_sensor_violations_result.to_string())\n",
    "# result.to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
